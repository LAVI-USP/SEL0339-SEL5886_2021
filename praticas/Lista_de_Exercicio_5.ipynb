{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lista_de_Exercicio_5.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NyvxHviMpShq"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGlmyFQMaR-U"
      },
      "source": [
        "# Lista de Exercício 5\n",
        "### Introdução à Visão Computacional (SEL0339/SEL5886)\n",
        "\n",
        "**Instruções:**\n",
        "\n",
        " 1. Esta lista consiste de 5 exercícios.\n",
        " 1. Deve-se colocar comentários nos códigos desenvolvidos.\n",
        " 1. As perguntas devem ser respondidas também como comentários no arquivo.\n",
        " 1. Colocar seu nome e número USP abaixo.\n",
        " 1. Quaisquer problemas na execução das listas, entrar em contato com os monitores.\n",
        " 1. Depois de terminado os exercícios, deve ser gerado um arquivo **extensão .ipynb** para ser enviado ao professor pelo E-DISCIPLINAS da disciplina até a data máxima de entrega.\n",
        " 1. Caso não seja enviado, o aluno ficará sem nota.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        " <table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/LAVI-USP/SEL0339-SEL5886/blob/master/praticas/Lista_de_Exercicio_5.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Executar no Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/LAVI-USP/SEL0339-SEL5886/blob/master/praticas/Lista_de_Exercicio_5.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />Ver codigo fonte no GitHub</a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3qYz1dB-tlT"
      },
      "source": [
        "`Nome: `\n",
        "\n",
        "`Número USP: `"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9uBe7nevota"
      },
      "source": [
        "### Introdução:\n",
        "\n",
        "Esta lista de exercícios abordará o tema de imagens coloridas. \n",
        "\n",
        "No modelo *red*, *green* e *blue* (RGB), cada cor aparece em seus componentes espectrais primários de vermelho, verde e azul. As imagens representadas nesse modelo de cores consistem em três imagens componentes, uma para cada cor primária, como mostra a Figura 1. Quando alimentados em um monitor RGB, essas três imagens se combinam na tela para produzir uma imagem colorida composta. Essa imagem colorida pode ser representada computacionalmente por uma matriz tridimensional, onde os cada fatia da terceira dimensão representa um respectivo canal.\n",
        "\n",
        "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/5/56/RGB_channels_separation.png\" style=\"width:650px;height:300px;\"></center>\n",
        "\n",
        "<center><caption><b> Figura 1:</b> Ilustração dos componentes espectrais primários vermelho, verde e azul em uma imagem colorida.</b></caption></center>\n",
        "\n",
        "A espaço de cor *hue*, *saturation* e *value* (HSV - matiz, saturação e valor) é uma representação alternativa do modelo de cores RGB. Nesse modelo, as cores de cada matiz são dispostas em uma fatia radial, em torno de um eixo central de cores neutras que vai do preto na parte inferior ao branco na parte superior, como ilustrado pela Figura 2. A dimensão de saturação se assemelha a vários matizes de tinta colorida e a dimensão de valor se assemelha à mistura dessas tintas com quantidades variáveis de tinta preta ou branca. o modelo HSV é uma ferramenta útil para o desenvolvimento de algoritmos de processamento de imagem baseados em descrições de cores naturais e intuitivas para humanos, que, afinal, são os desenvolvedores e usuários desses algoritmos.\n",
        "\n",
        "<center><img src=\"https://miro.medium.com/max/700/0*zh_KZ220_5YvNdda.png\" width=\"379\" height=\"284\"></center>\n",
        "\n",
        "<center><caption><b> Figura 2:</b> Modelo espacial para representação do espaço de cores HSV.</b></caption></center>\n",
        "\n",
        "Referências:\n",
        "\n",
        "*   Material da sala de aula;\n",
        "*   Gonzalez and Woods, Digital Image Processing 4th;\n",
        "*   OpenCV: [Changing Color-space](https://docs.opencv.org/master/df/d9d/tutorial_py_colorspaces.html);\n",
        "\n",
        "Vamos importar as bibliotecas que iremos utilizar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnKV2As4aCX1"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "import os\n",
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyvxHviMpShq"
      },
      "source": [
        "#### **Atenção**: os códigos abaixo são para fazer o download das imagens (EXECUTE-OS). Os mesmos não fazem parte dessa prática. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Amk5CM273Afp"
      },
      "source": [
        "import urllib.request\n",
        "\n",
        "try:\n",
        "  urllib.request.urlretrieve(\"https://github.com/LAVI-USP/SEL0339-SEL5886_2021/raw/main/imagens/pratica_05/bird.png\", \"bird.png\")\n",
        "except:\n",
        "  print(\"[ERRO] Não foi possível fazer o download das imagens dessa prática. Entre em contato com o monitor\")\n",
        "\n",
        "try:\n",
        "  urllib.request.urlretrieve(\"https://github.com/LAVI-USP/SEL0339-SEL5886_2021/raw/main/imagens/pratica_05/canal.png\", \"canal.png\")\n",
        "except:\n",
        "  print(\"[ERRO] Não foi possível fazer o download das imagens dessa prática. Entre em contato com o monitor\")\n",
        "\n",
        "try:\n",
        "  urllib.request.urlretrieve(\"https://github.com/LAVI-USP/SEL0339-SEL5886_2021/raw/main/imagens/pratica_05/paprika.png\", \"paprika.png\")\n",
        "except:\n",
        "  print(\"[ERRO] Não foi possível fazer o download das imagens dessa prática. Entre em contato com o monitor\")\n",
        "\n",
        "try:\n",
        "  urllib.request.urlretrieve(\"https://github.com/LAVI-USP/SEL0339-SEL5886_2021/raw/main/imagens/pratica_05/megaman.gif\", \"megaman.gif\")\n",
        "except:\n",
        "  print(\"[ERRO] Não foi possível fazer o download das imagens dessa prática. Entre em contato com o monitor\")\n",
        "\n",
        "try:\n",
        "  urllib.request.urlretrieve(\"https://github.com/LAVI-USP/SEL0339-SEL5886_2021/raw/main/imagens/pratica_05/borboleta.bmp\", \"borboleta.bmp\")\n",
        "except:\n",
        "  print(\"[ERRO] Não foi possível fazer o download das imagens dessa prática. Entre em contato com o monitor\")\n",
        "\n",
        "try:\n",
        "  urllib.request.urlretrieve(\"https://github.com/LAVI-USP/SEL0339-SEL5886_2021/raw/main/imagens/pratica_05/borboleta.gif\", \"borboleta.gif\")\n",
        "except:\n",
        "  print(\"[ERRO] Não foi possível fazer o download das imagens dessa prática. Entre em contato com o monitor\")\n",
        "\n",
        "try:\n",
        "  urllib.request.urlretrieve(\"https://github.com/LAVI-USP/SEL0339-SEL5886_2021/raw/main/imagens/pratica_05/ball-tracking-animated-02.gif\", \"ball-tracking-animated-02.gif\")\n",
        "except:\n",
        "  print(\"[ERRO] Não foi possível fazer o download das imagens dessa prática. Entre em contato com o monitor\")\n",
        "\n",
        "try:\n",
        "  urllib.request.urlretrieve(\"https://github.com/LAVI-USP/SEL0339-SEL5886_2021/raw/main/imagens/pratica_05/ball_tracking_example.mp4\", \"ball_tracking_example.mp4\")\n",
        "except:\n",
        "  print(\"[ERRO] Não foi possível fazer o download das imagens dessa prática. Entre em contato com o monitor\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHz3lrkyumoo"
      },
      "source": [
        "### 1) Imagens RGB\n",
        "\n",
        "1.1) Espaço em memória das imagens.\n",
        "\n",
        "**Exercício:**\n",
        "\n",
        "1. Faça a leitura da imagem ```paprika.png```, transforme-a para escala de cinza e mostre ambas na tela.\n",
        "2. Salve a imagem, tanto em **RGB** quanto em **escala de cinza**, no formato *bitmap* (bmp). Utilize os nomes ```paprika_rgb.bmp``` e ```paprika_gray.bmp``` para cada arquivo.\n",
        "3. Compare o **tamanho em bytes** da imagem em ```.png``` e as duas em ```.bmp```. Mostre na tela a razão entre as duas imagens em *bitmap*. Utilize o formato ```A razão entre a imagem paprika_rgb e paprika_gray é de XX vezes```.\n",
        "\n",
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkblue\"><b>Dicas:</b></font>\n",
        "</summary>\n",
        "\n",
        "*  A função ```cv.imread```, quando configurada para ler imagens coloridas, retorna os canais no formato ```BGR```. No entanto, a função ```plt.imshow``` trabalha somente no formato ```RGB```. Faça a transformação necessária. Pra isso, você pode utilizar técnicas regulares de programação ou a função [cv.cvtColor](https://docs.opencv.org/3.4/d8/d01/group__imgproc__color__conversions.html#ga397ae87e1288a81d2363b61574eb8cab). A tabela com todas as transformações possíveis estão nesse [link](https://docs.opencv.org/3.4/d8/d01/group__imgproc__color__conversions.html). \n",
        "*  Você pode utilizar a função [cv.imwrite](https://docs.opencv.org/3.4/d4/da8/group__imgcodecs.html#gabbc7ef1aa2edfaa87772f1202d67e0ce) para salvar as imagens.\n",
        "*  Utilize ```os.path.getsize``` para calcular o tamanho do arquivo da imagem. \n",
        "*  Você pode utilizar o argumento ```axis=-1``` da função ```np.mean``` para calcular a média aritmética ao longo do último eixo. \n",
        "\n",
        "*Ex:*\n",
        "``` python\n",
        "cv.cvtColor(myImg, cv.COLOR_space2space)\n",
        "cv.imwrite(\"myImg.tif\", myImg)\n",
        "print(\"{} bytes\".format(os.path.getsize(\"myImg.tif\")))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWg6jEzMD3xN"
      },
      "source": [
        "## -- Seu código começa AQUI -- ##\n",
        "\n",
        "## -- Seu código termina AQUI -- ##"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWAJLdx8zSTV"
      },
      "source": [
        "### 2) Formato das imagens\n",
        "\n",
        "Alguns dos formatos existentes para imagens coloridas:\n",
        "\n",
        "*   O formato BMP - *Windows Bitmap*. Um formato de arquivo utilizado pra simples imagens sem compressão. Guarda a informação de quantos pixels a imagem contém e a cor de cada um expressa por 3 canais, cada um podendo assumir valor de 0 a 255 (para codificação em 8 bits).Item da lista\n",
        "*   O formato JPG tem seu nome por utilizar o padrão de compressão JPEG (*Joint Photographic Experts Group*) para imagens de qualidade fotográfica. É um dos métodos mais populares de compactação de imagens na Internet. Seu sistema de codificação divide a imagem em blocos e os compara com padrões base da transformada discreta do cosseno (DCT) e estabelece o peso da presença de cada um desses padrões em cada bloco.\n",
        "*   O formato GIF (*Graphic Interchange Format*). É freqüentemente usado para fazer pequenas animações e filmes curtos de baixa resolução para a Internet. Ideal para gráficos, logos e desenhos. Nesse padrão de compressão as cores são representadas por um conjunto de apenas 256 cores, sem a utilização de 3 canais RGB, como se dá com o uso do BMP.\n",
        "\n",
        "Mais detalhes no capítulo 8 - Compressão de Imagem e Marca d'Água do livro: Gonzalez and Woods, Digital Image Processing 4th.\n",
        "\n",
        "**Exercício:**\n",
        "\n",
        "1. Faça a leitura da imagem ```megaman.gif```, salve-a nos formatos *.jpg* e *.bmp*. Em seguida, compare o tamanho dos arquivos das imagens imprimindo a quantidade de bytes de cada um.\n",
        "2. Apresente as três imagens lado a lado em um tamanho que seja possível observar os detalhes nos valores dos pixels. Comente sobre as diferenças de memória utilizada e características visuais. Se achar necessário, selecione apenas uma região para plotar (como se fosse um zoom).\n",
        "3. Faça a leitura da imagem ```borboleta.bmp```e salve-a no formato *.jpg*. Uma versão *.gif* já é fornecida, basta carregá-la. Da mesma forma como no exercício 2, plote as 3 imagens e comente sobre diferenças e tamanhos. Comente os resultados e diferenças.\n",
        "\n",
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkblue\"><b>Dicas:</b></font>\n",
        "</summary>\n",
        "\n",
        "*  A função ```cv.imread```, quando configurada para ler imagens coloridas, retorna os canais no formato ```BGR```. No entanto, a função ```plt.imshow``` trabalha somente no formato ```RGB```. Faça a transformação necessária. Pra isso, você pode utilizar técnicas regulares de programação ou a função [cv.cvtColor](https://docs.opencv.org/3.4/d8/d01/group__imgproc__color__conversions.html#ga397ae87e1288a81d2363b61574eb8cab). A tabela com todas as transformações possíveis estão nesse [link](https://docs.opencv.org/3.4/d8/d01/group__imgproc__color__conversions.html). \n",
        "*  Você pode utilizar a função [cv.imwrite](https://docs.opencv.org/3.4/d4/da8/group__imgcodecs.html#gabbc7ef1aa2edfaa87772f1202d67e0ce) para salvar as imagens.\n",
        "*  Utilize ```os.path.getsize``` para calcular o tamanho do arquivo da imagem.  \n",
        "*  Para carregar imagens *.gif* é necessário utilizar outra função do OpenCV, que não a imread. PAra tanto, utilize a função cv.VideoCapture(\"arquivo.gif\"), conforme exemplo:\n",
        "\n",
        "*Ex:*\n",
        "``` python\n",
        "captura = cv.VideoCapture(\"megaman_1.gif\")\n",
        "ret, img = captura.read()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC7cTlFBxeOM"
      },
      "source": [
        "## -- Seu código começa AQUI -- ##\n",
        "\n",
        "## -- Seu código termina AQUI -- ##"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOOMbcy_F_TV"
      },
      "source": [
        "### 3) Transformação de espaço de cores\n",
        "\n",
        "**Exercício:**\n",
        "\n",
        "1. Decomponha a imagem ```bird.png``` em suas três componentes RGB. Mostre cada uma delas. Utilize a função ```cv.imread``` para a leitura.\n",
        "2. Transforme-a para HSV e mostre cada componente.\n",
        "3. Transforme-a para CMY e mostre cada componente.\n",
        "4. Utilize *subplot* para organizar as imagens, sendo 1 linha para cada espaço de cor. Coloque título em todas as imagens. \n",
        "\n",
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkblue\"><b>Dicas:</b></font>\n",
        "</summary>\n",
        "\n",
        "*  Utilize a função [plt.subplot](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplot.html) para criar *subplots*. \n",
        "*  Utilize a função [plt.title](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.title.html) para colocar título nas imagens.\n",
        " \n",
        "\n",
        "*Ex:*\n",
        "``` python\n",
        "# Cria um subplot com 2 linhas e 2 colunas. \n",
        "# O último argumento especifica qual plot você irá utilizar\n",
        "plt.subplot(2,2,1) \n",
        "\n",
        "plt.title(\"Meu título aqui\")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrD4oic0GWqA"
      },
      "source": [
        "## -- Seu código começa AQUI -- ##\n",
        "\n",
        "## -- Seu código termina AQUI -- ##"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D3t2YekZzVk"
      },
      "source": [
        "### 4) Filtragem de imagens coloridas\n",
        "\n",
        "4.1) Filtro passa-baixa.\n",
        "\n",
        "**Exercício:**\n",
        "\n",
        "1. Filtrar a imagem ```canal.png``` em RGB com o filtro da média $13\\times13$.\n",
        "2. Converter a imagem de RGB para HSV, separar as componentes, filtrar a componente (V) com o mesmo filtro anterior, recompor a imagem HSV e reconverter para RGB.\n",
        "3. Filtrar as 3 componentes (H, S e V) separadamente e reconverter para RGB.\n",
        "4. Mostre a imagem original e os resultados anteriores. Utilize *subplot*. O que se pode concluir?\n",
        "\n",
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkblue\"><b>Dicas:</b></font>\n",
        "</summary>\n",
        "\n",
        "*  Você pode utilizar a função [np.stack](https://numpy.org/doc/stable/reference/generated/numpy.stack.html) para empilhar os diferentes canais. O argumento `axis` especifica em qual dimensão as imagens serão empilhadas. Caso seja especificado como `-1`, a última dimensão será utilizada.\n",
        "\n",
        "* A função [cv.blur](https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html#ga8c45db9afe636703801b0b2e440fce37) pode ser útil para o filtro da média.\n",
        " \n",
        "\n",
        "*Ex:*\n",
        "``` python\n",
        "np.stack((A,B),axis=-1)\n",
        "cv.blur(myImg,(kSize,kSize))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4oOLWudEGvj"
      },
      "source": [
        "## -- Seu código começa AQUI -- ##\n",
        "\n",
        "## -- Seu código termina AQUI -- ##"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-KPx5I8Y7CE"
      },
      "source": [
        "4.2) Filtro passa-alta.\n",
        "\n",
        "**Exercício:**\n",
        "\n",
        "1. Faça os mesmos passos do exercício anterior, porém utilizando um filtro de aguçamento de $3\\times3$.\n",
        "2. Faça a diferença entre a imagem original e as filtradas.\n",
        "3. Mostre a imagem original e os resultados. Utilize *subplot*. O que se pode concluir?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYt-hFICY7Og"
      },
      "source": [
        "## -- Seu código começa AQUI -- ##\n",
        "\n",
        "## -- Seu código termina AQUI -- ##"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wblYTghrnf-P"
      },
      "source": [
        "### 5) Aplicação\n",
        "\n",
        "Você faz parte de um projeto cujo objetivo é rastrear a trajetória de uma bola de cor verde em um vídeo. Sua tarefa será gerar um vídeo que detecte e isole a bola utilizando visão computacional.\n",
        "\n",
        "Um trecho do vídeo utilizado como entrada para o código pode ser visto a seguir.\n",
        "\n",
        "<center><img src=\"https://github.com/LAVI-USP/SEL0339-SEL5886_2021/blob/main/imagens/pratica_05/ball-tracking-animated-02.gif?raw=true\\\" style=\"width:531px;height:317px;\"></center>\n",
        "\n",
        "<center><caption><b> Figura 3:</b> Movimento da bola.</b></caption></center>\n",
        "\n",
        "Sua tarefa será fazer o pré-processamento da imagem, passando um filtro passa-baixa e entregando os frames para o restante do código em HSV. Em seguida, no código já pronto, será aplicada uma máscara levando em consideração níveis de verde claro até escuro.\n",
        "\n",
        "Caso queira obter mais informações sobre o projeto, visite esse [blog](https://www.pyimagesearch.com/2015/09/14/ball-tracking-with-opencv/).\n",
        "\n",
        "**Exercício:**\n",
        "\n",
        "1. Aplique um filtro Gaussiano de modo a eliminar altas frequências e focar em objetos estruturais da imagem. Converta o frame filtrado de RGB para HSV. \n",
        "\n",
        "Obs: Varie o tamanho do *kernel* e verifique o resultado.\n",
        "\n",
        "*Dicas:* \n",
        "  *   Utilize a função [cv.GaussianBlur](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#gaabe8c836e97159a9193fb0b11ac52cf1);\n",
        "  *   Caso rode o código novamente, certifique-se sempre que excluir o arquivo \"ball_tracking_example_out_compressed.mp4\" antes de gerar um novo. Sobrescrever o arquivo pode causar erro.\n",
        "\n",
        "*Ex:*\n",
        "``` python\n",
        "cv.GaussianBlur(myImg,(ksize,ksize),0)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GD7wMBlqLX6"
      },
      "source": [
        "# Execute este código se quiser ver o vídeo original\n",
        "mp4 = open(\"ball_tracking_example.mp4\",'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dlef9ozOhEHo"
      },
      "source": [
        "greenLower = (29,86,6) #verde escuro\n",
        "greenUpper = (64, 255, 162) #verde claro\n",
        "# Cria o objeto VideoCapture\n",
        "vs = cv.VideoCapture( \"ball_tracking_example.mp4\")\n",
        "# Defina o codec e cria o objeto VideoWriter. A saída é armazenada no arquivo 'ball_tracking_example_out.mp4'.\n",
        "out = cv.VideoWriter(\"ball_tracking_example_out.mp4\",cv.VideoWriter_fourcc(* \"MP4V\" ), 20.0, (432,240))\n",
        "\n",
        "#Percorre todos os frames\n",
        "while True:\n",
        "  # Leitura do frame\n",
        "  ret, frame = vs.read()\n",
        "  # Caso nao tenha mais nenhum frame\n",
        "  if frame is None :\n",
        "    break\n",
        "  frame = cv.resize(frame,(432,240)) # Para processar mais rápido o frame\n",
        "\n",
        "  ## -- Seu código começa AQUI -- input frame ##\n",
        "  blurred = \n",
        "  hsv =   \n",
        "  ## -- Seu código termina AQUI -- output hsv ##\n",
        "\n",
        "  mask = cv.inRange(hsv, greenLower, greenUpper)\n",
        "  mask = cv.erode(mask, None, iterations = 2)\n",
        "  mask = cv.dilate(mask, None, iterations = 2)\n",
        "  res = cv.bitwise_and(frame, frame, mask = mask)\n",
        "  # Escreve o frame no arquivo\n",
        "  out.write(res)\n",
        "\n",
        "out.release()\n",
        "\n",
        "os.system(f\"ffmpeg -i ball_tracking_example_out.mp4 -vcodec libx264 ball_tracking_example_out_compressed.mp4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3iWqHBXumzy"
      },
      "source": [
        "# Execute este código se quiser ver o vídeo original\n",
        "mp4 = open(\"ball_tracking_example_out_compressed.mp4\",'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}